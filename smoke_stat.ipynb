{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predicting Smoker Status Based on BioSignals</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Importing Libraries </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.1       , 0.10816327, 0.11632653, 0.1244898 , 0.13265306,\n",
       "        0.14081633, 0.14897959, 0.15714286, 0.16530612, 0.17346939,\n",
       "        0.18163265, 0.18979592, 0.19795918, 0.20612245, 0.21428571,\n",
       "        0.22244898, 0.23061224, 0.23877551, 0.24693878, 0.25510204,\n",
       "        0.26326531, 0.27142857, 0.27959184, 0.2877551 , 0.29591837,\n",
       "        0.30408163, 0.3122449 , 0.32040816, 0.32857143, 0.33673469,\n",
       "        0.34489796, 0.35306122, 0.36122449, 0.36938776, 0.37755102,\n",
       "        0.38571429, 0.39387755, 0.40204082, 0.41020408, 0.41836735,\n",
       "        0.42653061, 0.43469388, 0.44285714, 0.45102041, 0.45918367,\n",
       "        0.46734694, 0.4755102 , 0.48367347, 0.49183673, 0.5       ]),\n",
       " 0.00816326530612245)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.1, 0.5, retstep=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Exploration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>...</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>75</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>165</td>\n",
       "      <td>65</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>126</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>93</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>180</td>\n",
       "      <td>95</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>102</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>80.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>93</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age  height(cm)  weight(kg)  waist(cm)  eyesight(left)   \n",
       "0   0   55         165          60       81.0             0.5  \\\n",
       "1   1   70         165          65       89.0             0.6   \n",
       "2   2   20         170          75       81.0             0.4   \n",
       "3   3   35         180          95      105.0             1.5   \n",
       "4   4   30         165          60       80.5             1.5   \n",
       "\n",
       "   eyesight(right)  hearing(left)  hearing(right)  systolic  ...  HDL  LDL   \n",
       "0              0.6              1               1       135  ...   40   75  \\\n",
       "1              0.7              2               2       146  ...   57  126   \n",
       "2              0.5              1               1       118  ...   45   93   \n",
       "3              1.2              1               1       131  ...   38  102   \n",
       "4              1.0              1               1       121  ...   44   93   \n",
       "\n",
       "   hemoglobin  Urine protein  serum creatinine  AST  ALT  Gtp  dental caries   \n",
       "0        16.5              1               1.0   22   25   27              0  \\\n",
       "1        16.2              1               1.1   27   23   37              1   \n",
       "2        17.4              1               0.8   27   31   53              0   \n",
       "3        15.9              1               1.0   20   27   30              1   \n",
       "4        15.4              1               0.8   19   13   17              0   \n",
       "\n",
       "   smoking  \n",
       "0        1  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159256, 24)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159256 entries, 0 to 159255\n",
      "Data columns (total 24 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id                   159256 non-null  int64  \n",
      " 1   age                  159256 non-null  int64  \n",
      " 2   height(cm)           159256 non-null  int64  \n",
      " 3   weight(kg)           159256 non-null  int64  \n",
      " 4   waist(cm)            159256 non-null  float64\n",
      " 5   eyesight(left)       159256 non-null  float64\n",
      " 6   eyesight(right)      159256 non-null  float64\n",
      " 7   hearing(left)        159256 non-null  int64  \n",
      " 8   hearing(right)       159256 non-null  int64  \n",
      " 9   systolic             159256 non-null  int64  \n",
      " 10  relaxation           159256 non-null  int64  \n",
      " 11  fasting blood sugar  159256 non-null  int64  \n",
      " 12  Cholesterol          159256 non-null  int64  \n",
      " 13  triglyceride         159256 non-null  int64  \n",
      " 14  HDL                  159256 non-null  int64  \n",
      " 15  LDL                  159256 non-null  int64  \n",
      " 16  hemoglobin           159256 non-null  float64\n",
      " 17  Urine protein        159256 non-null  int64  \n",
      " 18  serum creatinine     159256 non-null  float64\n",
      " 19  AST                  159256 non-null  int64  \n",
      " 20  ALT                  159256 non-null  int64  \n",
      " 21  Gtp                  159256 non-null  int64  \n",
      " 22  dental caries        159256 non-null  int64  \n",
      " 23  smoking              159256 non-null  int64  \n",
      "dtypes: float64(5), int64(19)\n",
      "memory usage: 29.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>...</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "      <td>159256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79627.500000</td>\n",
       "      <td>44.306626</td>\n",
       "      <td>165.266929</td>\n",
       "      <td>67.143662</td>\n",
       "      <td>83.001990</td>\n",
       "      <td>1.005798</td>\n",
       "      <td>1.000989</td>\n",
       "      <td>1.023974</td>\n",
       "      <td>1.023421</td>\n",
       "      <td>122.503648</td>\n",
       "      <td>...</td>\n",
       "      <td>55.852684</td>\n",
       "      <td>114.607682</td>\n",
       "      <td>14.796965</td>\n",
       "      <td>1.074233</td>\n",
       "      <td>0.892764</td>\n",
       "      <td>25.516853</td>\n",
       "      <td>26.550296</td>\n",
       "      <td>36.216004</td>\n",
       "      <td>0.197996</td>\n",
       "      <td>0.437365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45973.391572</td>\n",
       "      <td>11.842286</td>\n",
       "      <td>8.818970</td>\n",
       "      <td>12.586198</td>\n",
       "      <td>8.957937</td>\n",
       "      <td>0.402113</td>\n",
       "      <td>0.392299</td>\n",
       "      <td>0.152969</td>\n",
       "      <td>0.151238</td>\n",
       "      <td>12.729315</td>\n",
       "      <td>...</td>\n",
       "      <td>13.964141</td>\n",
       "      <td>28.158931</td>\n",
       "      <td>1.431213</td>\n",
       "      <td>0.347856</td>\n",
       "      <td>0.179346</td>\n",
       "      <td>9.464882</td>\n",
       "      <td>17.753070</td>\n",
       "      <td>31.204643</td>\n",
       "      <td>0.398490</td>\n",
       "      <td>0.496063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39813.750000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79627.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119441.250000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159255.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>1860.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>778.000000</td>\n",
       "      <td>2914.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id            age     height(cm)     weight(kg)   \n",
       "count  159256.000000  159256.000000  159256.000000  159256.000000  \\\n",
       "mean    79627.500000      44.306626     165.266929      67.143662   \n",
       "std     45973.391572      11.842286       8.818970      12.586198   \n",
       "min         0.000000      20.000000     135.000000      30.000000   \n",
       "25%     39813.750000      40.000000     160.000000      60.000000   \n",
       "50%     79627.500000      40.000000     165.000000      65.000000   \n",
       "75%    119441.250000      55.000000     170.000000      75.000000   \n",
       "max    159255.000000      85.000000     190.000000     130.000000   \n",
       "\n",
       "           waist(cm)  eyesight(left)  eyesight(right)  hearing(left)   \n",
       "count  159256.000000   159256.000000    159256.000000  159256.000000  \\\n",
       "mean       83.001990        1.005798         1.000989       1.023974   \n",
       "std         8.957937        0.402113         0.392299       0.152969   \n",
       "min        51.000000        0.100000         0.100000       1.000000   \n",
       "25%        77.000000        0.800000         0.800000       1.000000   \n",
       "50%        83.000000        1.000000         1.000000       1.000000   \n",
       "75%        89.000000        1.200000         1.200000       1.000000   \n",
       "max       127.000000        9.900000         9.900000       2.000000   \n",
       "\n",
       "       hearing(right)       systolic  ...            HDL            LDL   \n",
       "count   159256.000000  159256.000000  ...  159256.000000  159256.000000  \\\n",
       "mean         1.023421     122.503648  ...      55.852684     114.607682   \n",
       "std          0.151238      12.729315  ...      13.964141      28.158931   \n",
       "min          1.000000      77.000000  ...       9.000000       1.000000   \n",
       "25%          1.000000     114.000000  ...      45.000000      95.000000   \n",
       "50%          1.000000     121.000000  ...      54.000000     114.000000   \n",
       "75%          1.000000     130.000000  ...      64.000000     133.000000   \n",
       "max          2.000000     213.000000  ...     136.000000    1860.000000   \n",
       "\n",
       "          hemoglobin  Urine protein  serum creatinine            AST   \n",
       "count  159256.000000  159256.000000     159256.000000  159256.000000  \\\n",
       "mean       14.796965       1.074233          0.892764      25.516853   \n",
       "std         1.431213       0.347856          0.179346       9.464882   \n",
       "min         4.900000       1.000000          0.100000       6.000000   \n",
       "25%        13.800000       1.000000          0.800000      20.000000   \n",
       "50%        15.000000       1.000000          0.900000      24.000000   \n",
       "75%        15.800000       1.000000          1.000000      29.000000   \n",
       "max        21.000000       6.000000          9.900000     778.000000   \n",
       "\n",
       "                 ALT            Gtp  dental caries        smoking  \n",
       "count  159256.000000  159256.000000  159256.000000  159256.000000  \n",
       "mean       26.550296      36.216004       0.197996       0.437365  \n",
       "std        17.753070      31.204643       0.398490       0.496063  \n",
       "min         1.000000       2.000000       0.000000       0.000000  \n",
       "25%        16.000000      18.000000       0.000000       0.000000  \n",
       "50%        22.000000      27.000000       0.000000       0.000000  \n",
       "75%        32.000000      44.000000       0.000000       1.000000  \n",
       "max      2914.000000     999.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'height(cm)', 'weight(kg)', 'waist(cm)', 'eyesight(left)',\n",
       "       'eyesight(right)', 'hearing(left)', 'hearing(right)', 'systolic',\n",
       "       'relaxation', 'fasting blood sugar', 'Cholesterol', 'triglyceride',\n",
       "       'HDL', 'LDL', 'hemoglobin', 'Urine protein', 'serum creatinine', 'AST',\n",
       "       'ALT', 'Gtp', 'dental caries', 'smoking'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <td>0.686645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">weight(kg)</th>\n",
       "      <th>height(cm)</th>\n",
       "      <td>0.686645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waist(cm)</th>\n",
       "      <td>0.830208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <td>0.830208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systolic</th>\n",
       "      <th>relaxation</th>\n",
       "      <td>0.753003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relaxation</th>\n",
       "      <th>systolic</th>\n",
       "      <td>0.753003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>LDL</th>\n",
       "      <td>0.808533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDL</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <td>0.808533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <td>0.623408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <td>0.623408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "level_0     level_1              \n",
       "height(cm)  weight(kg)   0.686645\n",
       "weight(kg)  height(cm)   0.686645\n",
       "            waist(cm)    0.830208\n",
       "waist(cm)   weight(kg)   0.830208\n",
       "systolic    relaxation   0.753003\n",
       "relaxation  systolic     0.753003\n",
       "Cholesterol LDL          0.808533\n",
       "LDL         Cholesterol  0.808533\n",
       "AST         ALT          0.623408\n",
       "ALT         AST          0.623408"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = df.corr()\n",
    "corr_df = corr_df.stack().reset_index()\n",
    "corr_df = corr_df[corr_df.level_1 != corr_df.level_0]\n",
    "corr_df = corr_df.set_index([\"level_0\", \"level_1\"])\n",
    "corr_df = corr_df[abs(corr_df[0]) >= 0.6]\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corelated Features are:\n",
    "1. Height and weight\n",
    "2. Waist and weight\n",
    "3. Systolic and relaxation\n",
    "4. Cholestrol and LDL\n",
    "5. AST and ALT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_list = [\"height(cm)\", \"weight(kg)\", \"systolic\", \"relaxation\", \"Cholesterol\", \"LDL\", \"AST\", \"ALT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing Procedures </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits Data into Features and Target Variable\n",
    "# args: df\n",
    "# returns: modified _df \n",
    "def split_data(data):\n",
    "    y = df[\"smoking\"]\n",
    "    X = data.drop(columns=[\"smoking\", \"id\"])\n",
    "    return X,y\n",
    "#Scales Features within the data using Sklearn Standard Scaler (Maintains Column info)\n",
    "# args: df\n",
    "# returns: scaled Dataframe \n",
    "def scaler_function(data):\n",
    "    scl = StandardScaler()\n",
    "    cols = data.columns\n",
    "    X = pd.DataFrame(scl.fit_transform(data))\n",
    "    X.columns = cols\n",
    "    return X\n",
    "\n",
    "#Performs PCA on the dataset\n",
    "# args: data, pca_list(list of features to perfrom PCA on)\n",
    "#returns: PCAed Dataset\n",
    "\n",
    "def pca_function(data, feat_list, var_preserved):\n",
    "\n",
    "    pca_data = data[pca_list]\n",
    "    data = data.drop(columns=pca_list)\n",
    "\n",
    "    pca = PCA(n_components=var_preserved)\n",
    "    fitted_data = pd.DataFrame(pca.fit_transform(pca_data))\n",
    "    fitted_data = fitted_data.add_prefix(\"pca_comp_\")\n",
    "     \n",
    "    return pd.concat([fitted_data, data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    X,y = split_data(df)\n",
    "    X = scaler_function(X)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>relaxation</th>\n",
       "      <th>...</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.902985</td>\n",
       "      <td>-0.030268</td>\n",
       "      <td>-0.567581</td>\n",
       "      <td>-0.223489</td>\n",
       "      <td>-1.257856</td>\n",
       "      <td>-1.022156</td>\n",
       "      <td>-0.156725</td>\n",
       "      <td>-0.154865</td>\n",
       "      <td>0.981702</td>\n",
       "      <td>1.125777</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604429</td>\n",
       "      <td>-1.135246</td>\n",
       "      <td>-1.406581</td>\n",
       "      <td>1.189928</td>\n",
       "      <td>-0.213401</td>\n",
       "      <td>0.597927</td>\n",
       "      <td>-0.371570</td>\n",
       "      <td>-0.087326</td>\n",
       "      <td>-0.295342</td>\n",
       "      <td>-0.496866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.169636</td>\n",
       "      <td>-0.030268</td>\n",
       "      <td>-0.170319</td>\n",
       "      <td>0.669577</td>\n",
       "      <td>-1.009169</td>\n",
       "      <td>-0.767247</td>\n",
       "      <td>6.380587</td>\n",
       "      <td>6.457242</td>\n",
       "      <td>1.845852</td>\n",
       "      <td>0.681066</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.097105</td>\n",
       "      <td>0.082162</td>\n",
       "      <td>0.404573</td>\n",
       "      <td>0.980315</td>\n",
       "      <td>-0.213401</td>\n",
       "      <td>1.155511</td>\n",
       "      <td>0.156700</td>\n",
       "      <td>-0.199983</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>2.012614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.052535</td>\n",
       "      <td>0.536694</td>\n",
       "      <td>0.624205</td>\n",
       "      <td>-0.223489</td>\n",
       "      <td>-1.506543</td>\n",
       "      <td>-1.277064</td>\n",
       "      <td>-0.156725</td>\n",
       "      <td>-0.154865</td>\n",
       "      <td>-0.353802</td>\n",
       "      <td>-0.208355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.048274</td>\n",
       "      <td>-0.777185</td>\n",
       "      <td>-0.767350</td>\n",
       "      <td>1.818767</td>\n",
       "      <td>-0.213401</td>\n",
       "      <td>-0.517239</td>\n",
       "      <td>0.156700</td>\n",
       "      <td>0.250645</td>\n",
       "      <td>0.537870</td>\n",
       "      <td>-0.496866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.785883</td>\n",
       "      <td>1.670617</td>\n",
       "      <td>2.213252</td>\n",
       "      <td>2.455708</td>\n",
       "      <td>1.229017</td>\n",
       "      <td>0.507296</td>\n",
       "      <td>-0.156725</td>\n",
       "      <td>-0.154865</td>\n",
       "      <td>0.667465</td>\n",
       "      <td>1.236955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.138923</td>\n",
       "      <td>-1.278470</td>\n",
       "      <td>-0.447734</td>\n",
       "      <td>0.770702</td>\n",
       "      <td>-0.213401</td>\n",
       "      <td>0.597927</td>\n",
       "      <td>-0.582878</td>\n",
       "      <td>0.025331</td>\n",
       "      <td>-0.199202</td>\n",
       "      <td>2.012614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.208100</td>\n",
       "      <td>-0.030268</td>\n",
       "      <td>-0.567581</td>\n",
       "      <td>-0.279305</td>\n",
       "      <td>1.229017</td>\n",
       "      <td>-0.002521</td>\n",
       "      <td>-0.156725</td>\n",
       "      <td>-0.154865</td>\n",
       "      <td>-0.118125</td>\n",
       "      <td>-0.097177</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.613639</td>\n",
       "      <td>-0.848797</td>\n",
       "      <td>-0.767350</td>\n",
       "      <td>0.421347</td>\n",
       "      <td>-0.213401</td>\n",
       "      <td>-0.517239</td>\n",
       "      <td>-0.688532</td>\n",
       "      <td>-0.763267</td>\n",
       "      <td>-0.615808</td>\n",
       "      <td>-0.496866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  height(cm)  weight(kg)  waist(cm)  eyesight(left)   \n",
       "0  0.902985   -0.030268   -0.567581  -0.223489       -1.257856  \\\n",
       "1  2.169636   -0.030268   -0.170319   0.669577       -1.009169   \n",
       "2 -2.052535    0.536694    0.624205  -0.223489       -1.506543   \n",
       "3 -0.785883    1.670617    2.213252   2.455708        1.229017   \n",
       "4 -1.208100   -0.030268   -0.567581  -0.279305        1.229017   \n",
       "\n",
       "   eyesight(right)  hearing(left)  hearing(right)  systolic  relaxation  ...   \n",
       "0        -1.022156      -0.156725       -0.154865  0.981702    1.125777  ...  \\\n",
       "1        -0.767247       6.380587        6.457242  1.845852    0.681066  ...   \n",
       "2        -1.277064      -0.156725       -0.154865 -0.353802   -0.208355  ...   \n",
       "3         0.507296      -0.156725       -0.154865  0.667465    1.236955  ...   \n",
       "4        -0.002521      -0.156725       -0.154865 -0.118125   -0.097177  ...   \n",
       "\n",
       "   triglyceride       HDL       LDL  hemoglobin  Urine protein   \n",
       "0      2.604429 -1.135246 -1.406581    1.189928      -0.213401  \\\n",
       "1     -1.097105  0.082162  0.404573    0.980315      -0.213401   \n",
       "2      1.048274 -0.777185 -0.767350    1.818767      -0.213401   \n",
       "3      1.138923 -1.278470 -0.447734    0.770702      -0.213401   \n",
       "4     -0.613639 -0.848797 -0.767350    0.421347      -0.213401   \n",
       "\n",
       "   serum creatinine       AST       ALT       Gtp  dental caries  \n",
       "0          0.597927 -0.371570 -0.087326 -0.295342      -0.496866  \n",
       "1          1.155511  0.156700 -0.199983  0.025124       2.012614  \n",
       "2         -0.517239  0.156700  0.250645  0.537870      -0.496866  \n",
       "3          0.597927 -0.582878  0.025331 -0.199202       2.012614  \n",
       "4         -0.517239 -0.688532 -0.763267 -0.615808      -0.496866  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = preprocessing(df)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Feature Selection </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf =  RandomForestClassifier()\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([x for x in range(len(rf.feature_importances_))], rf.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hemoglobin', 'height(cm)', 'Gtp'], dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most important features\n",
    "X.columns[pd.Series(rf.feature_importances_).nlargest(3).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([6, 7, 16], dtype='int64')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#least important features\n",
    "drop_feats = pd.Series(rf.feature_importances_).nsmallest(3)\n",
    "drop_feats = drop_feats.index\n",
    "drop_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159256, 19)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.drop(columns=X.columns[drop_feats])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Model Selection and Evaluation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores: \", scores)\n",
    "    print(\"Mean: \", np.mean(scores))\n",
    "    print(\"Std Dev: \", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model Evaluation \n",
    "rf = RandomForestClassifier()\n",
    "scores = cross_val_score(rf, X, y, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.77527314 0.7709406  0.77891498 0.77213362 0.77558709 0.77389175\n",
      " 0.7766405  0.77745683 0.78210361 0.76872841]\n",
      "Mean:  0.7751670534305937\n",
      "Std Dev:  0.0037404773911770685\n"
     ]
    }
   ],
   "source": [
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB Model Evaluation\n",
    "clf = xgb.XGBClassifier()\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.78192892 0.77740801 0.784001   0.77791034 0.78299636 0.7807359\n",
      " 0.77965463 0.78549451 0.78568289 0.77814757]\n",
      "Mean:  0.781396012681099\n",
      "Std Dev:  0.0029475528696114566\n"
     ]
    }
   ],
   "source": [
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Model Evaluation\n",
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.74645234 0.74356398 0.74927791 0.74368956 0.75021977 0.74795931\n",
      " 0.74737834 0.75466248 0.75830455 0.74518053]\n",
      "Mean:  0.7486688780980953\n",
      "Std Dev:  0.0044905427708539876\n"
     ]
    }
   ],
   "source": [
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Nearest Neighbors Model Evaluation\n",
    "clf = KNeighborsClassifier()\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.73326636 0.72868266 0.73471054 0.73012684 0.73640588 0.73590355\n",
      " 0.73029827 0.73934066 0.73343799 0.73155416]\n",
      "Mean:  0.7333726901361497\n",
      "Std Dev:  0.0031355799950985113\n"
     ]
    }
   ],
   "source": [
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.73326636 0.72868266 0.73471054 0.73012684 0.73640588 0.73590355\n",
      " 0.73029827 0.73934066 0.73343799 0.73155416]\n",
      "Mean:  0.7333726901361497\n",
      "Std Dev:  0.0031355799950985113\n"
     ]
    }
   ],
   "source": [
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Model Evaluation\n",
    "clf = GaussianNB()\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.72133618 0.71913852 0.72805475 0.72215246 0.72265478 0.72416175\n",
      " 0.72822606 0.72797488 0.72747253 0.72      ]\n",
      "Mean:  0.7241171899627614\n",
      "Std Dev:  0.003376397179576235\n"
     ]
    }
   ],
   "source": [
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Model Tuning </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will select these models for my ensemble method:\n",
    "    1. Logisitic Regression\n",
    "    2. XGBoost\n",
    "    3. Guassian NB / KNN (I will tune both and decide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Log Reg Model Finetuning </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "375 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "260 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of LogisticRegression must be a float in the range (0, inf]. Got array([0.        , 0.03061224, 0.06122449, 0.09183673, 0.12244898,\n",
      "       0.15306122, 0.18367347, 0.21428571, 0.24489796, 0.2755102 ,\n",
      "       0.30612245, 0.33673469, 0.36734694, 0.39795918, 0.42857143,\n",
      "       0.45918367, 0.48979592, 0.52040816, 0.55102041, 0.58163265,\n",
      "       0.6122449 , 0.64285714, 0.67346939, 0.70408163, 0.73469388,\n",
      "       0.76530612, 0.79591837, 0.82653061, 0.85714286, 0.8877551 ,\n",
      "       0.91836735, 0.94897959, 0.97959184, 1.01020408, 1.04081633,\n",
      "       1.07142857, 1.10204082, 1.13265306, 1.16326531, 1.19387755,\n",
      "       1.2244898 , 1.25510204, 1.28571429, 1.31632653, 1.34693878,\n",
      "       1.37755102, 1.40816327, 1.43877551, 1.46938776, 1.5       ]) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "                         ~~^~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.74894929        nan        nan\n",
      " 0.74895766 0.74893255        nan 0.74893255        nan 0.74895766\n",
      "        nan        nan        nan        nan        nan 0.74895766\n",
      "        nan        nan 0.74896604 0.7489158         nan        nan\n",
      " 0.74896604 0.74921721        nan        nan 0.7489158  0.74896604\n",
      "        nan 0.74896604        nan 0.7489158         nan        nan\n",
      "        nan        nan        nan        nan 0.74921721        nan\n",
      "        nan        nan 0.74920883        nan        nan 0.74896604\n",
      "        nan        nan        nan        nan        nan 0.7489158\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.7492507\n",
      "        nan 0.7489158         nan        nan        nan 0.74894929\n",
      "        nan        nan        nan        nan 0.7489158  0.74895766\n",
      "        nan 0.74896604        nan        nan 0.74896604        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan 0.74931976        nan        nan\n",
      " 0.7492444  0.74931348        nan 0.74931348        nan 0.7492444\n",
      "        nan        nan        nan        nan        nan 0.7492444\n",
      "        nan        nan 0.74924859 0.74931766        nan        nan\n",
      " 0.74923813 0.74940138        nan        nan 0.74931766 0.74923813\n",
      "        nan 0.74923813        nan 0.74931766        nan        nan\n",
      "        nan        nan        nan        nan 0.74940138        nan\n",
      "        nan        nan 0.74940138        nan        nan 0.74923813\n",
      "        nan        nan        nan        nan        nan 0.74931766\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.74940348\n",
      "        nan 0.74931766        nan        nan        nan 0.74931976\n",
      "        nan        nan        nan        nan 0.74931766 0.7492444\n",
      "        nan 0.74923813        nan        nan 0.74928417        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-31 {color: black;background-color: white;}#sk-container-id-31 pre{padding: 0;}#sk-container-id-31 div.sk-toggleable {background-color: white;}#sk-container-id-31 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-31 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-31 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-31 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-31 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-31 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-31 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-31 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-31 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-31 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-31 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-31 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-31 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-31 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-31 div.sk-item {position: relative;z-index: 1;}#sk-container-id-31 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-31 div.sk-item::before, #sk-container-id-31 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-31 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-31 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-31 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-31 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-31 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-31 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-31 div.sk-label-container {text-align: center;}#sk-container-id-31 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-31 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-31\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=100,\n",
       "                   param_distributions=[{&#x27;C&#x27;: (array([0.        , 0.03061224, 0.06122449, 0.09183673, 0.12244898,\n",
       "       0.15306122, 0.18367347, 0.21428571, 0.24489796, 0.2755102 ,\n",
       "       0.30612245, 0.33673469, 0.36734694, 0.39795918, 0.42857143,\n",
       "       0.45918367, 0.48979592, 0.52040816, 0.55102041, 0.58163265,\n",
       "       0.6122449 , 0.64285714, 0.67346939, 0.70408...\n",
       "       0.91836735, 0.94897959, 0.97959184, 1.01020408, 1.04081633,\n",
       "       1.07142857, 1.10204082, 1.13265306, 1.16326531, 1.19387755,\n",
       "       1.2244898 , 1.25510204, 1.28571429, 1.31632653, 1.34693878,\n",
       "       1.37755102, 1.40816327, 1.43877551, 1.46938776, 1.5       ]),\n",
       "                                               0.030612244897959183),\n",
       "                                         &#x27;max_iter&#x27;: range(100, 1000, 100),\n",
       "                                         &#x27;penalty&#x27;: [None, &#x27;l2&#x27;, &#x27;l1&#x27;,\n",
       "                                                     &#x27;elasticnet&#x27;],\n",
       "                                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cholesky&#x27;,\n",
       "                                                    &#x27;saga&#x27;]}],\n",
       "                   return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=100,\n",
       "                   param_distributions=[{&#x27;C&#x27;: (array([0.        , 0.03061224, 0.06122449, 0.09183673, 0.12244898,\n",
       "       0.15306122, 0.18367347, 0.21428571, 0.24489796, 0.2755102 ,\n",
       "       0.30612245, 0.33673469, 0.36734694, 0.39795918, 0.42857143,\n",
       "       0.45918367, 0.48979592, 0.52040816, 0.55102041, 0.58163265,\n",
       "       0.6122449 , 0.64285714, 0.67346939, 0.70408...\n",
       "       0.91836735, 0.94897959, 0.97959184, 1.01020408, 1.04081633,\n",
       "       1.07142857, 1.10204082, 1.13265306, 1.16326531, 1.19387755,\n",
       "       1.2244898 , 1.25510204, 1.28571429, 1.31632653, 1.34693878,\n",
       "       1.37755102, 1.40816327, 1.43877551, 1.46938776, 1.5       ]),\n",
       "                                               0.030612244897959183),\n",
       "                                         &#x27;max_iter&#x27;: range(100, 1000, 100),\n",
       "                                         &#x27;penalty&#x27;: [None, &#x27;l2&#x27;, &#x27;l1&#x27;,\n",
       "                                                     &#x27;elasticnet&#x27;],\n",
       "                                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cholesky&#x27;,\n",
       "                                                    &#x27;saga&#x27;]}],\n",
       "                   return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=100,\n",
       "                   param_distributions=[{'C': (array([0.        , 0.03061224, 0.06122449, 0.09183673, 0.12244898,\n",
       "       0.15306122, 0.18367347, 0.21428571, 0.24489796, 0.2755102 ,\n",
       "       0.30612245, 0.33673469, 0.36734694, 0.39795918, 0.42857143,\n",
       "       0.45918367, 0.48979592, 0.52040816, 0.55102041, 0.58163265,\n",
       "       0.6122449 , 0.64285714, 0.67346939, 0.70408...\n",
       "       0.91836735, 0.94897959, 0.97959184, 1.01020408, 1.04081633,\n",
       "       1.07142857, 1.10204082, 1.13265306, 1.16326531, 1.19387755,\n",
       "       1.2244898 , 1.25510204, 1.28571429, 1.31632653, 1.34693878,\n",
       "       1.37755102, 1.40816327, 1.43877551, 1.46938776, 1.5       ]),\n",
       "                                               0.030612244897959183),\n",
       "                                         'max_iter': range(100, 1000, 100),\n",
       "                                         'penalty': [None, 'l2', 'l1',\n",
       "                                                     'elasticnet'],\n",
       "                                         'solver': ['lbfgs', 'newton-cholesky',\n",
       "                                                    'saga']}],\n",
       "                   return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finetuning Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "param_grid = [\n",
    "    {\"penalty\": [None, \"l2\", \"l1\",\"elasticnet\"], \"solver\":[\"lbfgs\", \"newton-cholesky\", \"saga\"],\n",
    "   \"max_iter\": range(100, 1000, 100), \"C\": np.linspace(0.1, 1.5, retstep=0.1)}\n",
    "]\n",
    "random_search = RandomizedSearchCV(log_reg, param_grid, cv=5, scoring=\"accuracy\", return_train_score=True, n_iter=100)\n",
    "random_search.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-34 {color: black;background-color: white;}#sk-container-id-34 pre{padding: 0;}#sk-container-id-34 div.sk-toggleable {background-color: white;}#sk-container-id-34 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-34 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-34 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-34 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-34 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-34 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-34 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-34 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-34 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-34 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-34 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-34 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-34 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-34 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-34 div.sk-item {position: relative;z-index: 1;}#sk-container-id-34 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-34 div.sk-item::before, #sk-container-id-34 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-34 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-34 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-34 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-34 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-34 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-34 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-34 div.sk-label-container {text-align: center;}#sk-container-id-34 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-34 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-34\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=225, min_samples_leaf=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" checked><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=225, min_samples_leaf=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=225, min_samples_leaf=10)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5007487441806315"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "330 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of LogisticRegression must be a float in the range (0, inf]. Got array([0.        , 0.01020408, 0.02040816, 0.03061224, 0.04081633,\n",
      "       0.05102041, 0.06122449, 0.07142857, 0.08163265, 0.09183673,\n",
      "       0.10204082, 0.1122449 , 0.12244898, 0.13265306, 0.14285714,\n",
      "       0.15306122, 0.16326531, 0.17346939, 0.18367347, 0.19387755,\n",
      "       0.20408163, 0.21428571, 0.2244898 , 0.23469388, 0.24489796,\n",
      "       0.25510204, 0.26530612, 0.2755102 , 0.28571429, 0.29591837,\n",
      "       0.30612245, 0.31632653, 0.32653061, 0.33673469, 0.34693878,\n",
      "       0.35714286, 0.36734694, 0.37755102, 0.3877551 , 0.39795918,\n",
      "       0.40816327, 0.41836735, 0.42857143, 0.43877551, 0.44897959,\n",
      "       0.45918367, 0.46938776, 0.47959184, 0.48979592, 0.5       ]) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "                         ~~^~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.2510842  -0.25105071 -0.25110931 -0.25110094         nan -0.2512349\n",
      "         nan         nan -0.2510842  -0.25105071 -0.25110931 -0.25110094\n",
      "         nan -0.2512349          nan         nan -0.2510842  -0.25105071\n",
      " -0.25110931 -0.25110094         nan -0.2512349          nan         nan\n",
      " -0.2510842  -0.25105071 -0.25110931 -0.25110094         nan -0.2512349\n",
      "         nan         nan -0.2510842  -0.25105071 -0.25110931 -0.25110094\n",
      "         nan -0.2512349          nan         nan -0.2510842  -0.25105071\n",
      " -0.25110931 -0.25110094         nan -0.2512349          nan         nan]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.25068234 -0.25067815 -0.25079327 -0.25078071         nan -0.25092932\n",
      "         nan         nan -0.25068234 -0.25067815 -0.25079327 -0.25078071\n",
      "         nan -0.25092932         nan         nan -0.25068234 -0.25067606\n",
      " -0.25079327 -0.25078071         nan -0.25092932         nan         nan\n",
      " -0.25068234 -0.25067815 -0.25079327 -0.25078071         nan -0.25092932\n",
      "         nan         nan -0.25068234 -0.25068024 -0.25079327 -0.25078281\n",
      "         nan -0.25092932         nan         nan -0.25068234 -0.25067815\n",
      " -0.25079327 -0.25078071         nan -0.25092932         nan         nan]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-27 {color: black;background-color: white;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid=[{&#x27;C&#x27;: (array([0.        , 0.01020408, 0.02040816, 0.03061224, 0.04081633,\n",
       "       0.05102041, 0.06122449, 0.07142857, 0.08163265, 0.09183673,\n",
       "       0.10204082, 0.1122449 , 0.12244898, 0.13265306, 0.14285714,\n",
       "       0.15306122, 0.16326531, 0.17346939, 0.18367347, 0.19387755,\n",
       "       0.20408163, 0.21428571, 0.2244898 , 0.23469388, 0.24489796,\n",
       "       0.25510204,...\n",
       "       0.30612245, 0.31632653, 0.32653061, 0.33673469, 0.34693878,\n",
       "       0.35714286, 0.36734694, 0.37755102, 0.3877551 , 0.39795918,\n",
       "       0.40816327, 0.41836735, 0.42857143, 0.43877551, 0.44897959,\n",
       "       0.45918367, 0.46938776, 0.47959184, 0.48979592, 0.5       ]),\n",
       "                                0.01020408163265306),\n",
       "                          &#x27;max_iter&#x27;: range(350, 500, 25),\n",
       "                          &#x27;penalty&#x27;: [None, &#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;newton-cholesky&#x27;, &#x27;saga&#x27;]}],\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid=[{&#x27;C&#x27;: (array([0.        , 0.01020408, 0.02040816, 0.03061224, 0.04081633,\n",
       "       0.05102041, 0.06122449, 0.07142857, 0.08163265, 0.09183673,\n",
       "       0.10204082, 0.1122449 , 0.12244898, 0.13265306, 0.14285714,\n",
       "       0.15306122, 0.16326531, 0.17346939, 0.18367347, 0.19387755,\n",
       "       0.20408163, 0.21428571, 0.2244898 , 0.23469388, 0.24489796,\n",
       "       0.25510204,...\n",
       "       0.30612245, 0.31632653, 0.32653061, 0.33673469, 0.34693878,\n",
       "       0.35714286, 0.36734694, 0.37755102, 0.3877551 , 0.39795918,\n",
       "       0.40816327, 0.41836735, 0.42857143, 0.43877551, 0.44897959,\n",
       "       0.45918367, 0.46938776, 0.47959184, 0.48979592, 0.5       ]),\n",
       "                                0.01020408163265306),\n",
       "                          &#x27;max_iter&#x27;: range(350, 500, 25),\n",
       "                          &#x27;penalty&#x27;: [None, &#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;newton-cholesky&#x27;, &#x27;saga&#x27;]}],\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid=[{'C': (array([0.        , 0.01020408, 0.02040816, 0.03061224, 0.04081633,\n",
       "       0.05102041, 0.06122449, 0.07142857, 0.08163265, 0.09183673,\n",
       "       0.10204082, 0.1122449 , 0.12244898, 0.13265306, 0.14285714,\n",
       "       0.15306122, 0.16326531, 0.17346939, 0.18367347, 0.19387755,\n",
       "       0.20408163, 0.21428571, 0.2244898 , 0.23469388, 0.24489796,\n",
       "       0.25510204,...\n",
       "       0.30612245, 0.31632653, 0.32653061, 0.33673469, 0.34693878,\n",
       "       0.35714286, 0.36734694, 0.37755102, 0.3877551 , 0.39795918,\n",
       "       0.40816327, 0.41836735, 0.42857143, 0.43877551, 0.44897959,\n",
       "       0.45918367, 0.46938776, 0.47959184, 0.48979592, 0.5       ]),\n",
       "                                0.01020408163265306),\n",
       "                          'max_iter': range(350, 500, 25),\n",
       "                          'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
       "                          'solver': ['newton-cholesky', 'saga']}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Narrowing Down Hyperparameter Search\n",
    "param_grid = [\n",
    "    {\"penalty\": [None, \"l2\", \"l1\",\"elasticnet\"], \"solver\":[\"newton-cholesky\", \"saga\"],\n",
    "   \"max_iter\": range(350, 500, 25), \"C\": np.linspace(0.1, 0.5, retstep=0.05)}\n",
    "]\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/ismailrageh/Documents/WORK/sideprojects/kaggle/smoke_stat/smoke_stat.ipynb Cell 44\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ismailrageh/Documents/WORK/sideprojects/kaggle/smoke_stat/smoke_stat.ipynb#Y122sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m (grid_search\u001b[39m.\u001b[39;49mbest_estimator_)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5010496051353799"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Random Forest Model Finetuning </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_grid = [\n",
    "    {\"n_estimators\" : range(1,250, 25), \"criterion\": [\"gini\", \"entropy\", \"log_loss\"], \"max_depth\": range(1,250,25), \"min_samples_leaf\": range(1,50,5)}\n",
    "]\n",
    "random_search = RandomizedSearchCV(rf, param_grid, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True, n_iter=100)\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,1, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 101,\n",
       " 'min_samples_leaf': 11,\n",
       " 'max_depth': 201,\n",
       " 'criterion': 'log_loss'}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47301202887733246"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> KNN Model Finetuning </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ismailrageh/Documents/WORK/sideprojects/kaggle/smoke_stat/smoke_stat.ipynb Cell 51\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ismailrageh/Documents/WORK/sideprojects/kaggle/smoke_stat/smoke_stat.ipynb#Y141sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m param_grid \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ismailrageh/Documents/WORK/sideprojects/kaggle/smoke_stat/smoke_stat.ipynb#Y141sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mn_neighbors\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m100\u001b[39m)}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ismailrageh/Documents/WORK/sideprojects/kaggle/smoke_stat/smoke_stat.ipynb#Y141sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ismailrageh/Documents/WORK/sideprojects/kaggle/smoke_stat/smoke_stat.ipynb#Y141sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(knn,param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m,return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ismailrageh/Documents/WORK/sideprojects/kaggle/smoke_stat/smoke_stat.ipynb#Y141sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    705\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mfit_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    707\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[0;32m--> 708\u001b[0m test_scores \u001b[39m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[1;32m    709\u001b[0m score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[1;32m    710\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    765\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[1;32m    766\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[1;32m    768\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    770\u001b[0m         \u001b[39m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    771\u001b[0m         \u001b[39m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:234\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, estimator, X, y_true, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    212\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \n\u001b[1;32m    214\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_score(\n\u001b[1;32m    235\u001b[0m         partial(_cached_call, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    236\u001b[0m         estimator,\n\u001b[1;32m    237\u001b[0m         X,\n\u001b[1;32m    238\u001b[0m         y_true,\n\u001b[1;32m    239\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    240\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:276\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_score\u001b[39m(\u001b[39mself\u001b[39m, method_caller, estimator, X, y_true, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    249\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \n\u001b[1;32m    251\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m     y_pred \u001b[39m=\u001b[39m method_caller(estimator, \u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m, X)\n\u001b[1;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sign \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_score_func(\n\u001b[1;32m    279\u001b[0m             y_true, y_pred, sample_weight\u001b[39m=\u001b[39msample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs\n\u001b[1;32m    280\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:73\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(estimator, method)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m cache[method]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:234\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39m    Class labels for each data sample.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    232\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    235\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/neighbors/_base.py:824\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    817\u001b[0m use_pairwise_distances_reductions \u001b[39m=\u001b[39m (\n\u001b[1;32m    818\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    819\u001b[0m     \u001b[39mand\u001b[39;00m ArgKmin\u001b[39m.\u001b[39mis_usable_for(\n\u001b[1;32m    820\u001b[0m         X \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_\n\u001b[1;32m    821\u001b[0m     )\n\u001b[1;32m    822\u001b[0m )\n\u001b[1;32m    823\u001b[0m \u001b[39mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 824\u001b[0m     results \u001b[39m=\u001b[39m ArgKmin\u001b[39m.\u001b[39;49mcompute(\n\u001b[1;32m    825\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    826\u001b[0m         Y\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X,\n\u001b[1;32m    827\u001b[0m         k\u001b[39m=\u001b[39;49mn_neighbors,\n\u001b[1;32m    828\u001b[0m         metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_,\n\u001b[1;32m    829\u001b[0m         metric_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_params_,\n\u001b[1;32m    830\u001b[0m         strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    831\u001b[0m         return_distance\u001b[39m=\u001b[39;49mreturn_distance,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    834\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m    835\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprecomputed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m issparse(X)\n\u001b[1;32m    836\u001b[0m ):\n\u001b[1;32m    837\u001b[0m     results \u001b[39m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    838\u001b[0m         X, n_neighbors\u001b[39m=\u001b[39mn_neighbors, return_distance\u001b[39m=\u001b[39mreturn_distance\n\u001b[1;32m    839\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:277\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39mreturns.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m Y\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64:\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mreturn\u001b[39;00m ArgKmin64\u001b[39m.\u001b[39;49mcompute(\n\u001b[1;32m    278\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    279\u001b[0m         Y\u001b[39m=\u001b[39;49mY,\n\u001b[1;32m    280\u001b[0m         k\u001b[39m=\u001b[39;49mk,\n\u001b[1;32m    281\u001b[0m         metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m    282\u001b[0m         chunk_size\u001b[39m=\u001b[39;49mchunk_size,\n\u001b[1;32m    283\u001b[0m         metric_kwargs\u001b[39m=\u001b[39;49mmetric_kwargs,\n\u001b[1;32m    284\u001b[0m         strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    285\u001b[0m         return_distance\u001b[39m=\u001b[39;49mreturn_distance,\n\u001b[1;32m    286\u001b[0m     )\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m Y\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat32:\n\u001b[1;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m ArgKmin32\u001b[39m.\u001b[39mcompute(\n\u001b[1;32m    290\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[1;32m    291\u001b[0m         Y\u001b[39m=\u001b[39mY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         return_distance\u001b[39m=\u001b[39mreturn_distance,\n\u001b[1;32m    298\u001b[0m     )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:95\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/threadpoolctl.py:171\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mtype\u001b[39m, value, traceback):\n\u001b[1;32m    172\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestore_original_limits()\n\u001b[1;32m    174\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39mcls\u001b[39m, controller, \u001b[39m*\u001b[39m, limits\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, user_api\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    knn = KNeighborsClassifier()\n",
    "    param_grid = [\n",
    "        {\"n_neighbors\": range(1,100)}\n",
    "    ]\n",
    "    grid_search = GridSearchCV(knn,param_grid, cv=5,scoring=\"accuracy\",return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
